 [**Inicio**](../README.md) ★ /  `Sesi贸n 01`

<div align="center">
    <img src="../BEDU.JPG" alt="Sesion_01">
</div>

##  Objetivos

锔 El objetivo de esta sesi贸n es que desarrolles un entendimiento profundo de la regresi贸n lineal y la regresi贸n log铆stica, dos t茅cnicas esenciales en el campo del machine learning. Aprender谩s c贸mo se utilizan estos modelos para identificar patrones y relaciones en los datos, permiti茅ndote realizar predicciones precisas y tomar decisiones informadas basadas en datos. A trav茅s de la exploraci贸n de los algoritmos subyacentes y la comprensi贸n de la funci贸n de costo y el m茅todo de gradiente descendente, te preparar谩s para aplicar estos conceptos en diversos contextos, desde la predicci贸n de resultados financieros hasta la clasificaci贸n de clientes, potenciando tu capacidad para abordar problemas reales con herramientas anal铆ticas robustas.


---

 Material del prework:
En el prework podr谩s encontrar la parte te贸rica que utilizaremos para realizar los ejercicios de esta sesi贸n. 
ヂVamos a comenzar!

---

##  Temas de la sesi贸n...


###  Regresi贸n lineal 

La regresi贸n lineal te permite crear un modelo de un sistema al evaluar la relaci贸n entre las variables dependientes e independientes de un conjunto de datos de entrenamiento, logrando predicciones que son muy cercanas a la realidad. Este tipo de modelo tiene muchas aplicaciones, como predecir la temperatura de ma帽ana bas谩ndose en datos hist贸ricos, estimar el precio de mercado de una empresa, o prever el puntaje de una prueba de un ni帽o en funci贸n de las caracter铆sticas de su madre. La regresi贸n lineal es uno de los algoritmos m谩s conocidos y utilizados en el campo de la inteligencia artificial.

---

###  Funci贸n de costo

Una vez que se tiene el modelo para poder realizar las predicciones correspondientes, es necesario saber qu茅 tan cercana a la realidad es esa predicci贸n. Para ello, introducimos un concepto llamado funci贸n de costo, el cual, nos permite calcular el error que existe entre la predicci贸n hecha por la computadora y el valor real de nuestros datos. Al igual que un profesor califica un examen que los alumnos contestaron despu茅s de una noche de estudio (entrenamiento), un algoritmo supervisado calcula el error que existe entre las predicciones de la m谩quina y las respuestas reales. Utilizamos la funci贸n de costo para medir la exactitud de nuestra hip贸tesis, la cual est谩 definida como la diferencia promedio de todos los resultados de las hip贸tesis con entradas 


---

###  Gradiente descendente

El gradiente descendente es un algoritmo de optimizaci贸n utilizado para minimizar funciones matem谩ticas, especialmente en problemas de aprendizaje autom谩tico y redes neuronales. Su objetivo es encontrar los par谩metros del modelo que minimicen una funci贸n de costo o p茅rdida, que mide el error entre las predicciones del modelo y los valores reales.

###  Regresi贸n log铆stica

La regresi贸n log铆stica, a diferencia de lo que sugiere su nombre, no es un problema de regresi贸n en s铆, sino un problema de clasificaci贸n. Se llama regresi贸n log铆stica porque su formulaci贸n matem谩tica se asemeja mucho a la de la regresi贸n lineal. Este algoritmo se utiliza para realizar clasificaciones binarias, donde solo hay dos clases posibles, o clasificaciones multiclase, con m谩s de dos clases. Por ejemplo, en una clasificaci贸n binaria, la regresi贸n log铆stica se puede aplicar para detectar si un correo electr贸nico es spam o no, o para clasificar un tumor como maligno o benigno.


---

### 锔 Actividades

####  **[Actividad 01: Aplicaci贸n de Regresi贸n Lineal para Determinar el Precio de un Seguro](/Sesi贸n-03/Actividad-01/README.md)**
####  **[Actividad 02: Aplicaci贸n de Regresi贸n Lineal para Predecir el Precio de Coches](/Sesi贸n-03/Actividad-02/README.md)**
####  **[Actividad 03: Aplicaci贸n de Regresi贸n Log铆stica para Diagn贸stico de Diabetes](/Sesi贸n-03/Actividad-03/README.md)**
####  **[Actividad 04: Aplicaci贸n de Regresi贸n Log铆stica para Diagn贸stico de C谩ncer de Mama](/Sesi贸n-03/Actividad-04/README.md)**

---

猬锔 [**Anterior**](../Sesi贸n-02/README.md) | [**Siguiente**](../Sesi贸n-04/README.md)★
