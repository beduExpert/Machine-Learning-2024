游 [**Inicio**](../README.md) 俱뫮잺 / 游닀 `Sesi칩n 01`

<div align="center">
    <img src="../BEDU.JPG" alt="Sesion_01">
</div>

## 游꿢 Objetivos

丘뉦잺 El objetivo de esta sesi칩n es que desarrolles una comprensi칩n s칩lida de las redes neuronales convolucionales (CNNs) y sus componentes clave, como las capas de convoluci칩n, pooling, normalizaci칩n de lotes y funciones de activaci칩n. Al finalizar, ser치s capaz de identificar c칩mo estas capas interact칰an entre s칤 para extraer caracter칤sticas relevantes de los datos y c칩mo implementar t칠cnicas de regularizaci칩n, como el dropout, para mejorar el rendimiento del modelo. Adem치s, podr치s analizar y comparar arquitecturas de CNN populares, aplicando los conocimientos adquiridos a problemas reales de visi칩n por computadora.


---

游닂 Material del prework:
En el prework podr치s encontrar la parte te칩rica que utilizaremos para realizar los ejercicios de esta sesi칩n. 
游댠춰Vamos a comenzar!游댠

---

## 游늭 Temas de la sesi칩n...


### 游닀 쯈u칠 es una CNN?

Una Red Neuronal Convolucional (CNN, por sus siglas en ingl칠s) es una arquitectura de aprendizaje profundo dise침ada espec칤ficamente para trabajar con datos que presentan una estructura en forma de rejilla, como im치genes, videos o series temporales. Aunque comparten la misma filosof칤a b치sica que una red neuronal tradicional, las CNNs se distinguen por su capacidad de procesar y extraer autom치ticamente caracter칤sticas significativas de los datos, lo que las ha convertido en una herramienta esencial en el an치lisis de im치genes y la visi칩n por computadora.

---

### 游닀 Capas de una CNN

En una red neuronal convolucional (CNN), las capas juegan un papel crucial en el procesamiento y an치lisis de im치genes. Cada tipo de capa tiene una funci칩n espec칤fica que contribuye a la capacidad de la red para extraer y aprender caracter칤sticas relevantes de los datos. Las tres principales capas de una CNN son: la capa de convoluci칩n, la capa de pooling (o reserva) y la capa totalmente conectada.


---

### 游닀 Dropout

Dropout es una t칠cnica de regularizaci칩n que puedes utilizar en tus redes neuronales, incluyendo redes neuronales convolucionales (CNN), para mejorar su capacidad de generalizaci칩n y reducir el sobreajuste (overfitting). El dropout es una estrategia simple pero efectiva para evitar que tu red se ajuste demasiado a los datos de entrenamiento, lo que te ayudar치 a mejorar su rendimiento en datos no vistos.

---

### 游닀 Arquitecturas Benchmarking

Cuando trabajas en el desarrollo de modelos de aprendizaje profundo, es fundamental que utilices arquitecturas benchmarking. Estas arquitecturas son modelos de redes neuronales que han sido ampliamente evaluadas y comparadas en diversas tareas y conjuntos de datos est치ndar. Sirven como referencia para medir el rendimiento de tus propias t칠cnicas y modelos, y te proporcionan una base s칩lida para evaluar y mejorar tus algoritmos en 치reas como visi칩n por computadora, procesamiento de lenguaje natural y otras aplicaciones del aprendizaje autom치tico.


---

### 九勇 Actividades

#### 游늿 **[Actividad 01: Clasificaci칩n de Im치genes sobre el dataset CIFAR10](/Sesi칩n-05/Actividad-01/README.md)**
#### 游늿 **[Actividad 02: Clasificaci칩n de Im치genes sobre un Dataset Customizado](/Sesi칩n-05/Actividad-02/README.md)**


---

拘勇 [**Anterior**](../Sesi칩n-03/README.md) | [**Siguiente**](../Sesi칩n-05/README.md)俱뫮잺
